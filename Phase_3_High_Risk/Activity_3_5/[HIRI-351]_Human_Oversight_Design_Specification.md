[HIRI-351]
Author: Dipl. Ing. Marvie Demit
---

# Human Oversight Design Specification

**Source:** Activity_3_5


*(A document to be completed for each High-Risk AI system)*

| | |
| :--- | :--- |
| **System Name / ID:** | [e.g., Resume Screener / AI-003] |
| **System Owner:** | [Name] |
| **Product/UX Lead:** | [Name] |

| **1. Oversight Model** | |
| :--- | :--- |
| **Selected Model:** | [Human-in-the-Loop / Human-on-the-Loop / Human-in-Command] |
| **Justification:** | [Explain why this model is appropriate for the system's risks and intended use.] |

| **2. Information for the Overseer** | |
| :--- | :--- |
| **Information Provided:** | [List the key pieces of information the user will see. e.g., "The AI's confidence score for its recommendation," "The top 3 factors that influenced the AI's decision," "A link to the source data."] |

| **3. Overseer Actions & Controls** | |
| :--- | :--- |
| **Monitoring Actions:** | [Describe how the user monitors the system. e.g., "A real-time dashboard of system decisions."] |
| **Intervention Actions:** | [List the specific actions the user can take. e.g., "Override a specific recommendation," "Reject a specific output," "Flag a decision for manual review."] |
| **"Stop Button":** | [Describe the mechanism to stop the system's operation. e.g., "A prominent 'Stop Process' button that immediately halts the current operation."] |

| **4. User Training** | |
| :--- | :--- |
| **Required Training:** | [Describe the training required for users to effectively oversee the system. e.g., "A mandatory 2-hour training module on interpreting the AI's output and understanding common failure modes."] |