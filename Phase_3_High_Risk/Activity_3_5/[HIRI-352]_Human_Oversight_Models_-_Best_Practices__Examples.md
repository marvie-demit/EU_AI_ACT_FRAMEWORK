[HIRI-352]
Author: Dipl. Ing. Marvie Demit
---

# Human Oversight Models - Best Practices & Examples

**Source:** Activity_3_5


| Model | Description | Best For... | Example |
| :--- | :--- | :--- | :--- |
| **Human-in-the-Loop (HITL)** | The AI provides a recommendation or completes a sub-task, but a human must approve or make the final decision before the process can conclude. | High-stakes decisions where human judgment is paramount. | An AI system suggests a diagnosis based on a medical scan, but a radiologist must review and sign off on the final report. |
| **Human-on-the-Loop (HOTL)** | The AI operates autonomously, but a human actively supervises its operations and can intervene or override it at any time. | Real-time processes where the AI is generally reliable but requires monitoring for safety or quality. | A human supervisor monitors a fleet of autonomous delivery drones and can take manual control of any drone that goes off course. |
| **Human-in-Command (HIC)** | The AI provides a set of options or analyses, and the human operator chooses the course of action. The AI is an advisor, not a decision-maker. | Complex planning or strategic scenarios where the AI can analyze variables but the human sets the goal. | A logistics AI recommends three different delivery routes based on traffic and weather; the human dispatcher chooses the final route. |

**The "Stop Button" Principle:** Regardless of the model, every High-Risk AI system must have a clear, accessible, and effective mechanism for a human to stop the system's operation at any time to prevent an adverse outcome.