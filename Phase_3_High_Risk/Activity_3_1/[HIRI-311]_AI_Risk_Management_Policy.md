[HIRI-311]
Author: Dipl. Ing. Marvie Demit
---

# AI Risk Management Policy

**Source:** Activity_3_1


```markdown
# [Your Company Name] High-Risk AI Risk Management Policy

**Version:** 1.0
**Date:** [Date]
**Owner:** AI Governance Body

## 1. Purpose

This document describes the mandatory, continuous risk management system required by Article 9 of the EU AI Act. This process applies to all AI systems classified as High-Risk and is integral to their entire lifecycle.

## 2. Scope

This policy applies to all High-Risk AI systems identified in the AI System Inventory. It covers the entire lifecycle, from initial conception and training to deployment, operation, and post-market monitoring.

## 3. Framework

This policy is based on the principles of the **[Chosen Framework, e.g., NIST AI Risk Management Framework (AI RMF) 1.0]**.

## 4. Risk Management Process

The risk management process is a continuous, iterative cycle with four stages:

1.  **Identify:** Systematically identify risks to health, safety, and fundamental rights arising from the intended purpose and reasonably foreseeable misuse of the AI system.
2.  **Analyze & Evaluate:** Estimate and evaluate the identified risks by considering their potential severity and probability of occurrence.
3.  **Treat:** Adopt suitable risk management measures to mitigate the evaluated risks. This includes measures for risk control, information to users, and testing.
4.  **Monitor & Review:** Continuously monitor the effectiveness of the risk management measures and the overall risk profile of the system in the post-market phase.

All stages must be documented in the system-specific **AI Risk Register**.

## 5. Roles and Responsibilities

*   **AI Governance Body:** Oversees the policy and reviews all high-priority risks.
*   **System Owner:** Owns the Risk Register for their system and is responsible for executing the risk management process.
*   **Technical, Legal, Privacy, Security:** Act as expert advisors in the risk assessment process.

## 6. Review Cycle

Risk Registers for all High-Risk AI systems must be formally reviewed at least **annually** or upon any significant change to the system or its operational context.
```