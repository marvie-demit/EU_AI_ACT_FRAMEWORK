[FRMW-004]
Author: Dipl. Ing. Marvie Demit
---


# The EU AI Act: A Master Implementation Guide

**A Comprehensive, Step-by-Step Framework for Compliance**


## Introduction

This Master Implementation Guide provides a complete, actionable framework for organizations seeking to comply with the European Union's Artificial Intelligence Act (Regulation (EU) 2024/1689). Inspired by the WHO's Laboratory Quality Stepwise Implementation (LQSI) model, this guide breaks down the complex legal requirements into a series of manageable phases and granular activities.

### Framework Structure

The guide is structured into two parallel tracks:

**Track A: Risk-Based Implementation (For AI System Providers and Deployers)**
This track follows the risk-based approach of the AI Act, with progressively increasing compliance obligations.

*   **Phase 1: Foundational Governance & Minimal Risk Compliance (6 Activities)**
*   **Phase 2: Limited Risk Compliance (7 Activities)**
*   **Phase 3: High-Risk AI Compliance (10 Activities)**

**Track B: GPAI Parallel Track (For General-Purpose AI Model Providers)**
This track addresses the specific obligations for providers of GPAI models, which apply irrespective of the downstream risk level.

*   **GPAI Parallel Track (7 Activities)**

Each of the 30 activities in this guide is presented as a standalone module with a consistent structure:

1.  **Activity Summary:** A concise statement of the objective.
2.  **Activity Description:** Detailed explanation of the `Why`, `What`, `How`, and `Who`.
3.  **Supporting Materials:** Embedded, production-ready templates and links to relevant legal articles and standards.

## Table of Contents

*   **Track A: Risk-Based Implementation**
    *   **Phase 1: Foundational Governance & Minimal Risk Compliance**
        *   [Activity 1.1: Establish AI Governance Body](#activity-11-establish-ai-governance-body)
        *   [Activity 1.2: Develop AI Inventory Procedure](#activity-12-develop-ai-inventory-procedure)
        *   [Activity 1.3: Conduct Initial AI System Inventory](#activity-13-conduct-initial-ai-system-inventory)
        *   [Activity 1.4: Develop Risk Classification Procedure](#activity-14-develop-risk-classification-procedure)
        *   [Activity 1.5: Classify All Inventoried Systems](#activity-15-classify-all-inventoried-systems)
        *   [Activity 1.6: Draft and Adopt Voluntary Code of Conduct](#activity-16-draft-and-adopt-voluntary-code-of-conduct)
    *   **Phase 2: Limited Risk Compliance**
        *   [Activity 2.1: Identify User-Facing Limited-Risk Systems](#activity-21-identify-user-facing-limited-risk-systems)
        *   [Activity 2.2: Implement User Notification Mechanisms](#activity-22-implement-user-notification-mechanisms)
        *   [Activity 2.3: Identify AI Content Generation Systems](#activity-23-identify-ai-content-generation-systems)
        *   [Activity 2.4: Implement Content Labeling/Watermarking](#activity-24-implement-content-labelingwatermarking)
        *   [Activity 2.5: Identify Biometric/Emotion Recognition Systems](#activity-25-identify-biometricemotion-recognition-systems)
        *   [Activity 2.6: Implement Explicit Information & Consent](#activity-26-implement-explicit-information--consent)
        *   [Activity 2.7: Maintain Records of Transparency Measures](#activity-27-maintain-records-of-transparency-measures)
    *   **Phase 3: High-Risk AI Compliance**
        *   [Activity 3.1: Establish Formal Risk Management System](#activity-31-establish-formal-risk-management-system)
        *   [Activity 3.2: Implement Robust Data Governance Framework](#activity-32-implement-robust-data-governance-framework)
        *   [Activity 3.3: Create and Maintain Detailed Technical Documentation](#activity-33-create-and-maintain-detailed-technical-documentation)
        *   [Activity 3.4: Establish Formal Quality Management System (QMS)](#activity-34-establish-formal-quality-management-system-qms)
        *   [Activity 3.5: Implement Human Oversight Mechanisms](#activity-35-implement-human-oversight-mechanisms)
        *   [Activity 3.6: Ensure Technical Accuracy, Robustness & Cybersecurity](#activity-36-ensure-technical-accuracy-robustness--cybersecurity)
        *   [Activity 3.7: Enable Automatic Event Logging](#activity-37-enable-automatic-event-logging)
        *   [Activity 3.8: Perform Conformity Assessment](#activity-38-perform-conformity-assessment)
        *   [Activity 3.9: Register in EU Database](#activity-39-register-in-eu-database)
        *   [Activity 3.10: Establish Post-Market Monitoring System](#activity-310-establish-post-market-monitoring-system)
*   **Track B: GPAI Parallel Track**
    *   [GPAI Activity 1: Develop and Maintain Technical Documentation](#gpai-activity-1-develop-and-maintain-technical-documentation)
    *   [GPAI Activity 2: Create Downstream Provider Information](#gpai-activity-2-create-downstream-provider-information)
    *   [GPAI Activity 3: Establish a Policy on EU Copyright Law](#gpai-activity-3-establish-a-policy-on-eu-copyright-law)
    *   [GPAI Activity 4: Publish a Detailed Summary of Training Data](#gpai-activity-4-publish-a-detailed-summary-of-training-data)
    *   [GPAI Activity 5: Appoint an EU Representative](#gpai-activity-5-appoint-an-eu-representative)
    *   [GPAI Activity 6: Register the GPAI Model](#gpai-activity-6-register-the-gpai-model)
    *   [GPAI Activity 7: Cooperate with Authorities](#gpai-activity-7-cooperate-with-authorities)



## Activity 1.1: Establish AI Governance Body

**A Detailed Guide to Implementing Foundational AI Oversight**


### **1. Activity Summary**

Form a cross-functional team or committee responsible for overseeing AI compliance, risk management, and ethical guidelines across the organization.

### **2. Activity Description**

#### **Why should this activity be completed?**

Establishing a dedicated AI Governance Body is the cornerstone of a successful EU AI Act compliance program. Centralized oversight is critical for ensuring the consistent application of policies, managing complex risks, and demonstrating accountability to regulators. Without a formal governance structure, compliance efforts often become siloed, inefficient, and incomplete, leading to significant legal and financial risks. This body provides a single source of truth and authority for all AI-related matters, ensuring a holistic and strategic approach to AI adoption and risk management.

#### **What should be done?**

The primary output of this activity is a formally constituted AI Governance Body with a clear mandate and the authority to act. The key deliverables include:

1.  **AI Governance Body Charter:** A formal document defining the body's mission, scope, authority, responsibilities, and decision-making processes.
2.  **Defined Roles and Responsibilities:** A clear RACI (Responsible, Accountable, Consulted, Informed) matrix outlining the duties of the chairperson, core members, and advisory members.
3.  **Official Member Roster:** A list of appointed individuals and the departments they represent.
4.  **Meeting Cadence and Agenda:** A defined schedule for regular meetings (e.g., quarterly) and a standing agenda covering key governance topics.

#### **How should it be completed?**

This activity should be completed in the following chronological order:

1.  **Secure Executive Sponsorship:** Identify a C-level executive (e.g., Chief Legal Officer, Chief Technology Officer, or Chief Compliance Officer) to champion the initiative and provide the necessary authority and resources.
2.  **Identify Key Stakeholder Departments:** Map out all departments that are involved in the development, deployment, or oversight of AI systems. This typically includes Legal, Compliance, Privacy, IT/Cybersecurity, Data Science/Engineering, HR, and representatives from key business units that use AI.
3.  **Draft the AI Governance Body Charter:** The executive sponsor, in collaboration with the legal and compliance leads, should draft a charter using the template provided in the Supporting Materials section.
4.  **Nominate and Appoint Members:** Based on the stakeholder map, department heads should nominate suitable representatives with the requisite expertise and seniority. The executive sponsor formally appoints the members.
5.  **Appoint a Chairperson:** Designate a chairperson to lead the body. This individual should have strong leadership skills and a deep understanding of both the business and the regulatory landscape.
6.  **Schedule and Conduct the Inaugural Meeting:** The first meeting should be used to formally ratify the charter, introduce the members, and set the agenda for the first 90 days. Key initial tasks will include approving the procedures for Activities 1.2 (AI Inventory) and 1.4 (Risk Classification).
7.  **Establish Communication Channels:** Define how the governance body will report its findings and decisions to executive leadership and how it will communicate policies and guidance across the organization.

#### **Who can best complete the activity?**

This is a cross-functional effort that requires senior leadership involvement:

*   **Executive Sponsor (Accountable):** A C-level leader who provides top-down authority.
*   **Chairperson (Responsible):** A senior leader, such as a Chief Compliance Officer, Chief Risk Officer, or a dedicated Chief AI Officer, who will lead the body's operations.
*   **Core Members:** Director-level or senior manager representatives from:
    *   Legal & Privacy
    *   Cybersecurity
    *   Data Science / AI Engineering
    *   IT / Infrastructure
    *   Key Business Units (e.g., Marketing, Operations, Finance)
    *   Human Resources (especially if AI is used in hiring)
*   **Advisors (Consulted):** Subject matter experts who can be called upon as needed, including external legal counsel, ethics advisors, and specialized consultants.


### **3. Supporting Materials**

#### **Template: AI Governance Body Charter**

```markdown
# [Your Company Name] AI Governance Body Charter

**Version:** 1.0
**Date:** [Date]

## 1. Mission Statement

The mission of the [Your Company Name] AI Governance Body is to ensure that all Artificial Intelligence (AI) systems developed, deployed, or used by the company are aligned with our corporate values, ethical principles, and legal/regulatory obligations, including the EU AI Act. We are committed to fostering innovation while managing risks and promoting trustworthy AI.

## 2. Scope and Authority

This charter applies to all AI systems across the organization, including those procured from third-party vendors. The AI Governance Body is granted the authority by the executive leadership to:

*   Establish and enforce AI-related policies and standards.
*   Review and approve high-risk AI systems before deployment.
*   Halt or require remediation for any AI system that is non-compliant or poses an unacceptable risk.
*   Direct resources for AI compliance and risk mitigation activities.

## 3. Membership and Roles

*   **Executive Sponsor:** [Name, Title]
*   **Chairperson:** [Name, Title]
*   **Core Members:**
    *   Legal & Compliance: [Name, Title]
    *   Privacy: [Name, Title]
    *   Cybersecurity: [Name, Title]
    *   Data Science/AI Engineering: [Name, Title]
    *   [Business Unit 1]: [Name, Title]
    *   [Business Unit 2]: [Name, Title]

## 4. Responsibilities

The AI Governance Body shall be responsible for:

*   Maintaining the company-wide AI inventory.
*   Overseeing the risk classification of all AI systems.
*   Reviewing and approving risk assessments and mitigation plans for high-risk systems.
*   Serving as the primary decision-making body for AI-related escalations.
*   Staying current with AI regulations and ensuring company policies are updated accordingly.

## 5. Decision-Making and Meetings

*   The Body shall meet quarterly, with ad-hoc meetings as needed.
*   Decisions will be made by a majority vote of core members. The Chairperson holds the tie-breaking vote.
*   Meeting minutes will be recorded and distributed to all members and the executive leadership.

## 6. Approval

**Approved by:** [Name of Executive Sponsor], [Title]
**Date:** [Date]
```

#### **Template: RACI Matrix for AI Governance**

| Task / Decision | Executive Sponsor | Chairperson | Legal | Cybersecurity | Data Science | Business Unit |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **Approve AI Policy** | A | R | C | C | C | I |
| **Classify AI System Risk** | I | A | C | C | R | R |
| **Approve High-Risk System** | A | R | C | C | C | C |
| **Manage AI Inventory** | I | A | I | I | R | I |
| **Respond to Regulator** | A | R | R | C | I | I |

*   **R** = Responsible (Does the work)
*   **A** = Accountable (Owns the work)
*   **C** = Consulted (Provides input)
*   **I** = Informed (Kept up-to-date)

#### **Further Reading**

*   **NIST AI Risk Management Framework (AI RMF 1.0):** This is an essential resource for developing a structured approach to AI risk management. It provides a detailed vocabulary and methodology for identifying, assessing, and managing AI risks, which is a core function of the governance body. It is highly recommended that all members of the governance body familiarize themselves with this framework.
    *   **Link:** [https://www.nist.gov/itl/ai-risk-management-framework](https://www.nist.gov/itl/ai-risk-management-framework)

*   **The EU AI Act - Full Text:** For direct reference to the legal requirements that the governance body must enforce. Article 17 on Quality Management Systems is particularly relevant to the establishment of this body.
    *   **Link:** [https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)



## Activity 1.2: Develop AI Inventory Procedure

**A Detailed Guide to Standardizing AI System Identification and Documentation**


### **1. Activity Summary**

Create a standardized, formal procedure for identifying, documenting, and maintaining a comprehensive register of all AI systems used or developed within the organization.

### **2. Activity Description**

#### **Why should this activity be completed?**

A standardized AI Inventory Procedure is the bedrock of compliance with the EU AI Act. Without a formal process, the identification of AI systems becomes ad-hoc and unreliable, making it impossible to create a complete inventory (Activity 1.3) or perform accurate risk classifications (Activity 1.5). This procedure ensures that all business units use a consistent method to report AI systems, providing the AI Governance Body with the necessary data to perform its oversight function. It transforms AI identification from a one-time project into a continuous, repeatable business process, which is essential for ongoing compliance and risk management.

#### **What should be done?**

The primary deliverable of this activity is a formally approved **AI System Inventory Procedure** document. This document will serve as the official guide for the entire organization. Key components of this procedure include:

1.  **A clear definition** of what constitutes an "AI system" within the context of the organization and the EU AI Act.
2.  **A standardized data collection mechanism**, typically an "AI System Identification Form" or questionnaire.
3.  **A defined workflow** for how the form is submitted, reviewed, and entered into the central AI inventory.
4.  **Clear roles and responsibilities** for who is responsible for identifying and reporting AI systems.

#### **How should it be completed?**

This activity should be completed in the following chronological order:

1.  **Assign Responsibility:** The AI Governance Body (established in Activity 1.1) should assign the task of drafting the procedure to a specific sub-group, typically led by representatives from IT, Data Science, and Compliance.
2.  **Define "AI System":** The sub-group must first establish a clear, practical definition of an "AI system" based on the EU AI Act (Article 3) to ensure everyone knows what needs to be reported. This definition should be included in the procedure document.
3.  **Design the Data Collection Form:** Using the template provided below, the sub-group should create a standardized "AI System Identification Form." This form is the core of the procedure and must capture all necessary information for the inventory and preliminary risk assessment.
4.  **Draft the Procedure Document:** The sub-group will draft the full procedure document, outlining the end-to-end process: how to access the form, who is required to fill it out, where to submit it, and the review and approval workflow.
5.  **Review and Refine:** The draft procedure and form should be circulated among the full AI Governance Body and a pilot group of business users for feedback to ensure clarity and practicality.
6.  **Formal Approval:** The final procedure document must be formally reviewed and approved by the AI Governance Body. This approval should be documented in the meeting minutes.
7.  **Communicate the Procedure:** Once approved, the procedure must be communicated to all relevant department heads and personnel across the organization.

#### **Who can best complete the activity?**

*   **AI Governance Body (Accountable):** Owns the final approval and is accountable for the procedure's effectiveness.
*   **Drafting Sub-Group (Responsible):** A team led by representatives from IT, Data Science, and Compliance is responsible for drafting the procedure and the form.
*   **Department Heads (Consulted):** Key business unit leaders should be consulted during the drafting phase to ensure the procedure is practical for their teams.
*   **All Employees (Informed):** All employees should be made aware of the procedure and their potential responsibility to report AI systems.


### **3. Supporting Materials**

#### **Template: AI System Inventory Procedure Document**

```markdown
# [Your Company Name] AI System Inventory Procedure

**Version:** 1.0
**Date:** [Date]
**Owner:** AI Governance Body

## 1. Purpose

This document outlines the mandatory procedure for identifying, documenting, and maintaining a comprehensive inventory of all Artificial Intelligence (AI) systems used or developed by [Your Company Name]. This procedure is essential for ensuring compliance with the EU AI Act and managing AI-related risks.

## 2. Scope

This procedure applies to all departments, employees, and contractors of [Your Company Name]. It covers all AI systems, whether developed in-house, procured from third-party vendors, or embedded within other software products.

## 3. Definition of an AI System

For the purpose of this procedure, an "AI system" is defined as a machine-based system designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. (Based on EU AI Act, Article 3).

*Examples include: machine learning models, natural language processing (NLP) systems, computer vision systems, generative AI, etc.*

## 4. Procedure

1.  **Identification:** All business and technology teams are responsible for identifying any new or existing AI systems within their area of responsibility.
2.  **Documentation:** For each identified AI system, the responsible team must complete the official "AI System Identification Form" (see Appendix A).
3.  **Submission:** The completed form must be submitted to the AI Governance Body via [e.g., dedicated email address, service desk portal].
4.  **Review:** The AI Governance Body will review the submission for completeness and accuracy.
5.  **Inventory Entry:** Upon approval, the system will be formally entered into the central AI System Inventory.

## 5. Roles and Responsibilities

*   **System Owners/Business Units:** Responsible for identifying systems and completing the Identification Form.
*   **AI Governance Body:** Responsible for reviewing submissions, maintaining the central inventory, and overseeing this procedure.

## 6. Review Cycle

This procedure will be reviewed and updated annually by the AI Governance Body.

## Appendix A: AI System Identification Form

*(See template below)*
```

#### **Template: AI System Identification Form**

This form can be created using Microsoft Forms, Google Forms, or a similar tool for easy submission and data collection.

```markdown
# AI System Identification Form

Please complete this form for any new or existing AI system used or developed by your team.

**Section 1: Basic Information**

*   **System Name:** [Free text]
*   **System Owner (Individual & Department):** [Free text]
*   **Submission Date:** [Date]

**Section 2: System Description**

*   **What is the primary purpose of this AI system?** (e.g., predict customer churn, automate invoice processing, generate marketing copy)
    [Free text]
*   **Who are the primary users of this system?** (e.g., internal employees, customers, general public)
    [Multiple choice]
*   **Is this system developed in-house or procured from a third-party vendor?**
    *   [ ] In-house
    *   [ ] Third-Party Vendor
*   **If third-party, what is the vendor and product name?** [Free text]

**Section 3: Data and Inputs**

*   **What types of data does this system use to make decisions or generate outputs?** (Check all that apply)
    *   [ ] Personal Data (e.g., name, email, address)
    *   [ ] Sensitive Personal Data (e.g., health, biometric, race)
    *   [ ] Financial Data
    *   [ ] Anonymized/Aggregated Data
    *   [ ] Other (please specify)
*   **Where does this data come from?** (e.g., CRM, internal database, public websites)
    [Free text]

**Section 4: Preliminary Risk Information**

*   **Could this system have a significant impact on a person's employment, access to education, or access to essential services (e.g., credit, insurance)?**
    *   [ ] Yes
    *   [ ] No
    *   [ ] Unsure
*   **Does this system involve biometric identification or categorization of people?**
    *   [ ] Yes
    *   [ ] No
    *   [ ] Unsure

**--- Thank you for your submission. The AI Governance Body will review this information and follow up if necessary. ---**
```

#### **Further Reading**

*   **EU AI Act, Article 3 (Definitions):** Provides the legal definition of an "AI System" that must be the basis for your internal definition.
    *   **Link:** [https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)
*   **ISO/IEC TR 24028:2020 - Overview of trustworthiness in Artificial Intelligence:** This technical report provides useful concepts and vocabulary for thinking about AI systems, which can help in framing the questions in your identification form.
    *   **Link:** [https://www.iso.org/standard/77608.html](https://www.iso.org/standard/77608.html)



## Activity 1.3: Conduct Initial AI System Inventory

**A Detailed Guide to Executing the Organization-Wide AI Census**


### **1. Activity Summary**

Execute the approved "AI System Inventory Procedure" to create a comprehensive register of all AI systems currently in use or development across the organization, populating the central AI System Inventory.

### **2. Activity Description**

#### **Why should this activity be completed?**

This activity operationalizes the procedure developed in Activity 1.2. It is the practical, hands-on effort to create the single source of truth for all AI within the organization. A complete and accurate inventory is not just a best practice; it is the foundational prerequisite for compliance with the EU AI Act. Without knowing what AI systems you have, you cannot assess their risk, apply the correct controls, or report to regulators. This initial census provides the essential data needed for all subsequent compliance activities, from risk classification (Phase 1) to post-market monitoring (Phase 3).

#### **What should be done?**

The primary deliverable is the **Initial Populated AI System Inventory**. This is a living document, typically a spreadsheet or database, that contains a detailed record for every AI system identified across the company. It is the central register that the AI Governance Body will manage and maintain. Each entry in the inventory should contain, at a minimum, the information collected from the "AI System Identification Form."

#### **How should it be completed?**

This activity should be completed in the following chronological order:

1.  **Official Launch Communication:** The Chairperson of the AI Governance Body sends a formal communication (using the email template below) to all department heads, officially launching the AI inventory initiative. This email should state the purpose, mandatory nature, deadline, and link to the procedure and identification form from Activity 1.2.
2.  **Cascade Information:** Department heads are responsible for cascading this information to their teams and identifying individuals ("System Champions") responsible for documenting the AI systems within their respective areas.
3.  **Data Collection:** The designated System Champions use the "AI System Identification Form" to document each AI system. This may involve collaborating with technical leads, product managers, and procurement specialists.
4.  **Submission and Tracking:** As forms are submitted, a designated administrator from the AI Governance Body tracks the submissions against a list of expected departments to ensure full participation. They should follow up with any non-responsive departments.
5.  **Review for Completeness:** The AI Governance Body (or its designated sub-group) reviews each submitted form for clarity and completeness. If information is missing or unclear, the form is returned to the submitter with a request for clarification.
6.  **Populate the Central Inventory:** Once a submission is approved as complete, the information is formally entered as a new record in the central "AI System Inventory Register" (using the template below).
7.  **Report on Progress:** The AI Governance Body provides regular status updates to the Executive Sponsor on the progress of the inventory, highlighting any challenges or roadblocks.
8.  **Formal Closure:** Once the deadline is reached and all departments have been accounted for, the AI Governance Body formally closes the *initial* inventory phase and presents a summary report to executive leadership.

#### **Who can best complete the activity?**

*   **AI Governance Body (Accountable):** Owns the overall success of the inventory process and is accountable for the final, populated register.
*   **Department Heads & System Owners (Responsible):** Responsible for ensuring their teams identify and accurately document all AI systems using the provided form.
*   **IT / Data Science Teams (Consulted):** Can be consulted by business units to help identify embedded AI components in existing software or to clarify technical details.
*   **Executive Sponsor (Informed):** Kept informed of the progress and results of the inventory.


### **3. Supporting Materials**

#### **Template: AI System Inventory Register**

This register should be maintained in a collaborative tool like a shared spreadsheet (Excel, Google Sheets) or a dedicated governance platform.

| Inventory ID | System Name | System Owner (Dept) | Vendor | Purpose | Data Types Used | High-Risk Flag (Initial) | Date Added | Status |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **AI-001** | Customer Churn Predictor | Marketing | In-house | Predicts which customers are likely to cancel their subscription. | Personal Data, Financial Data | Yes | 2025-11-21 | Inventoried |
| **AI-002** | Zenith CRM v3.4 | Sales | Zenith Corp. | Core CRM software. | Personal Data | Unsure | 2025-11-22 | Under Review |
| **AI-003** | Resume Screener | HR | HireRight Inc. | Automatically screens and ranks job applicant resumes. | Personal Data, Sensitive Data | Yes | 2025-11-23 | Inventoried |
| **AI-004** | Marketing Copy Generator | Marketing | In-house (GPAI-based) | Generates ad copy and email subject lines. | Anonymized Data | No | 2025-11-24 | Inventoried |

**Field Descriptions:**
*   **Inventory ID:** A unique identifier assigned by the AI Governance Body.
*   **System Name:** The common name of the AI system.
*   **System Owner (Dept):** The business department accountable for the system.
*   **Vendor:** The third-party vendor, or "In-house" if developed internally.
*   **Purpose:** A brief, clear description of what the system does.
*   **Data Types Used:** A summary of the data types from the identification form (e.g., Personal, Sensitive, Financial).
*   **High-Risk Flag (Initial):** A preliminary flag (Yes/No/Unsure) based on the answers to the risk questions in the identification form. This is not the final classification.
*   **Date Added:** The date the system was formally added to the inventory.
*   **Status:** The current status of the entry (e.g., "Under Review," "Inventoried," "Decommissioned").

#### **Template: Communication Email to Department Heads**

```markdown
**Subject: Mandatory Action: Company-Wide AI System Inventory for EU AI Act Compliance**

Dear Department Heads,

As you know, [Your Company Name] is committed to the ethical and legal use of Artificial Intelligence. In preparation for the upcoming enforcement of the European Unionâ€™s AI Act, we are conducting a mandatory, company-wide inventory of all AI systems.

This initiative is being led by the AI Governance Body and has the full support of our executive leadership. A complete and accurate inventory is the critical first step in our compliance program.

**Action Required:**

You are required to ensure that all AI systems used or developed within your department are identified and documented. Please cascade this instruction to your teams and appoint individuals to carry out this task.

1.  **Review the Procedure:** Familiarize yourself with the official **AI System Inventory Procedure** here: [Link to Procedure Document from Activity 1.2]
2.  **Document Each System:** For each AI system, your team must complete the **AI System Identification Form** here: [Link to Online Form]

**Deadline:**

Please ensure all forms for your department are submitted by **[Date - e.g., 4 weeks from launch]**.

Failure to inventory a system may result in significant legal risk for the company. The AI Governance Body will be tracking submissions and will follow up with you directly.

Thank you for your immediate attention and cooperation in this critical compliance effort.

Best regards,

[Name of Chairperson]
Chairperson, AI Governance Body
on behalf of the Executive Sponsor, [Name of Executive Sponsor]
```

#### **Further Reading**

*   **EU AI Act, Article 28 (Obligations of users of high-risk AI systems):** This article outlines the responsibilities of users (deployers), which include using systems in accordance with their instructions and monitoring their operation. These obligations cannot be met without first knowing that you are using a high-risk system, which starts with the inventory.
    *   **Link:** [https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)



## Activity 1.4: Develop Risk Classification Procedure

**A Detailed Guide to Creating a Standardized AI Risk Classification Methodology**


### **1. Activity Summary**

Develop and document a standardized, step-by-step procedure for classifying every AI system in the inventory into one of the four risk tiers defined by the EU AI Act: Unacceptable, High, Limited, or Minimal.

### **2. Activity Description**

#### **Why should this activity be completed?**

This procedure is the analytical engine of your entire compliance program. The EU AI Act is built on a risk-based approach, and accurately classifying each AI system is the most critical step in determining your legal obligations. An incorrect classification can lead to significant non-compliance (if a high-risk system is classified as low-risk) or unnecessary over-compliance and expense (if a low-risk system is classified as high-risk). A formal, documented procedure ensures that classifications are consistent, defensible, and based on a clear interpretation of the law, providing an essential audit trail for regulators.

#### **What should be done?**

The primary deliverable is a formally approved **AI Risk Classification Procedure** document. This document will contain:

1.  **A clear, sequential decision-making framework** (typically a flowchart or decision tree) that maps directly to the criteria in the EU AI Act.
2.  **Definitions** of each risk category, with examples.
3.  **A defined workflow** for how classifications are proposed, reviewed, and formally approved.
4.  **Clear roles and responsibilities** for who performs the classification and who approves it.

#### **How should it be completed?**

This activity is led by the Legal/Compliance team, with input from technical experts.

1.  **Assign Responsibility:** The AI Governance Body assigns the Legal/Compliance lead to draft the procedure.
2.  **Legal Interpretation:** The Legal lead performs a detailed analysis of Articles 5, 6, 52, and Annexes II and III of the EU AI Act to understand the precise legal criteria for each risk tier.
3.  **Draft the Decision Tree:** Based on the legal analysis, the lead drafts a sequential decision tree. The logic must flow from highest risk to lowest (Unacceptable -> High -> Limited -> Minimal) to prevent misclassification.
4.  **Draft the Full Procedure:** The lead drafts the full procedure document, wrapping the decision tree in a formal process for application, review, and approval.
5.  **Technical and Business Review:** The draft procedure is reviewed by the AI Governance Body, with specific feedback sought from technical (Data Science, Engineering) and business stakeholders to ensure the criteria are understandable and can be practically applied.
6.  **Validation with Test Cases:** The procedure should be tested against a few sample AI systems from the inventory to ensure it produces the expected classifications.
7.  **Formal Approval:** The final procedure is formally approved by the AI Governance Body and becomes the official methodology for the organization.

#### **Who can best complete the activity?**

*   **AI Governance Body (Accountable):** Accountable for approving the final procedure and ensuring its correct application.
*   **Legal/Compliance Lead (Responsible):** Responsible for interpreting the law and drafting the procedure and decision tree.
*   **Data Science / Technical Leads (Consulted):** Provide input on the technical feasibility and interpretation of the criteria.
*   **System Owners / Business Units (Informed):** Will be the primary users of this procedure to classify their systems in the next activity.


### **3. Supporting Materials**

#### **Template: AI Risk Classification Procedure Document**

```markdown
# [Your Company Name] AI Risk Classification Procedure

**Version:** 1.0
**Date:** [Date]
**Owner:** AI Governance Body

## 1. Purpose

This document outlines the official procedure for classifying all AI systems at [Your Company Name] according to the risk-based framework of the EU AI Act.

## 2. Scope

This procedure applies to all AI systems listed in the company's AI System Inventory.

## 3. Procedure

For each AI system, the System Owner, in consultation with Legal/Compliance, will follow the **AI Risk Classification Decision Tree** (Appendix A) to determine the risk classification. The final classification must be documented in the **AI Risk Classification Justification Form** and approved by the AI Governance Body before being recorded in the AI System Inventory.

## Appendix A: AI Risk Classification Decision Tree

*(See template below)*
```

#### **Template: AI Risk Classification Decision Tree**

*This flowchart is the core of the procedure and should be followed sequentially.*

```mermaid
graph TD
    A[Start: AI System from Inventory] --> B{Step 1: Check for Unacceptable Risk (Art. 5)};
    B -->|Yes| C[Result: UNACCEPTABLE RISK - Prohibited];
    B -->|No| D{Step 2: Check for High-Risk Categories (Art. 6 & Annex III)};
    D -->|Yes| E{Does it pose a significant risk of harm to health, safety, or fundamental rights?};
    E -->|Yes| F[Result: HIGH-RISK];
    E -->|No| G[Result: MINIMAL RISK (Exempted High-Risk)];
    D -->|No| H{Step 3: Check for Limited Risk (Art. 52)};
    H -->|Yes| I[Result: LIMITED RISK];
    H -->|No| J[Step 4: Default to Minimal Risk];
    J --> K[Result: MINIMAL RISK];

    subgraph Step 1 Criteria
        B1[Manipulative techniques?]
        B2[Exploits vulnerabilities?]
        B3[Social scoring?]
        B4[Real-time remote biometric ID in public spaces?]
    end

    subgraph Step 2 Criteria
        D1[Is it a safety component of a product?]
        D2[Is it in a listed Annex III area? e.g., Biometric ID, Critical Infrastructure, Education, Employment, Essential Services, Law Enforcement, Migration, Justice]
    end

    subgraph Step 3 Criteria
        H1[Interacts with humans (chatbot)?]
        H2[Generates content (deepfake)?]
        H3[Infers emotions/biometric categorization?]
    end
```

#### **Further Reading**

*   **EU AI Act, Articles 5, 6, 52, and Annexes II & III:** These are the core legal texts that define the risk categories. A thorough understanding is essential.
    *   **Link:** [https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)
...
4R1689)
...
